[38;5;4mâ„¹ Saving to output directory: models/ner11_v1[0m
[38;5;4mâ„¹ Using GPU: 0[0m
[1m
=========================== Initializing pipeline ===========================[0m
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[38;5;2mâœ” Initialized pipeline[0m
[1m
============================= Training pipeline =============================[0m
[38;5;4mâ„¹ Pipeline: ['transformer', 'ner'][0m
[38;5;4mâ„¹ Initial learn rate: 0.0[0m
E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE 
---  ------  -------------  --------  ------  ------  ------  ------
Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors
  0       0        7112.03   3186.96    0.00    0.00    0.01    0.00
  0     200      297112.60  41365.78    0.00    0.00    0.00    0.00
  0     400       22409.52  19906.79    0.00    0.00    0.00    0.00
  0     600       21836.95  24389.04    0.00    0.00    0.00    0.00
  0     800        8078.95  12196.10    0.00    0.00    0.00    0.00
  0    1000       29563.74  15006.83    0.00    0.00    0.00    0.00
